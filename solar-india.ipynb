{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqupkZYoi-Un"
   },
   "source": [
    "### Data Analysis with Python: Zero to Pandas - Course Project Guidelines\n",
    "#### (remove this cell before submission)\n",
    "\n",
    "Make submissions here:  https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "\n",
    "This is the starter notebook for the course project for [Data Analysis with Python: Zero to Pandas](https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas). For the course project, you will pick a real-world dataset of your choice and apply the concepts learned in this course to perform exploratory data analysis. Use this starter notebook as an outline for your project (you can also start with an empty new notebook). Focus on the documentation and presentation - this Jupyter notebook will also serve as a project report, so make sure to include detailed explanations wherever possible using Markdown cells.\n",
    "\n",
    "#### Step 1: Select a real-world dataset \n",
    "\n",
    "- Find and download an interesting real-world dataset (see the Recommended Datasets section below for ideas). \n",
    "\n",
    "- The dataset should contain tabular data (rows & columns), preferably in CSV/JSON/XLS or other formats that can be read using Pandas. If it's not in a compatible format, you may have to write some code to convert it to a desired format.\n",
    "- The dataset should contain at least 3 columns and 150 rows of data. You can also combine data from multiple sources to create a large enough dataset.\n",
    "\n",
    "\n",
    "#### Step 2: Perform data preparation & cleaning\n",
    "\n",
    "- Load the dataset into a data frame using Pandas\n",
    "- Explore the number of rows & columns, ranges of values etc.\n",
    "- Handle missing, incorrect and invalid data\n",
    "- Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.)\n",
    "\n",
    "\n",
    "#### Step 3: Perform exploratory Analysis & Visualization\n",
    "\n",
    "- Compute the mean, sum, range and other interesting statistics for numeric columns\n",
    "- Explore distributions of numeric columns using histograms etc.\n",
    "- Explore relationship between columns using scatter plots, bar charts etc.\n",
    "- Make a note of interesting insights from the exploratory analysis\n",
    "\n",
    "#### Step 4: Ask & answer questions about the data\n",
    "\n",
    "- Ask at least 5 interesting questions about your dataset\n",
    "- Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib/Seaborn\n",
    "- Create new columns, merge multiple datasets and perform grouping/aggregation wherever necessary\n",
    "- Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does\n",
    "\n",
    "\n",
    "#### Step 5: Summarize your inferences & write a conclusion\n",
    "\n",
    "- Write a summary of what you've learned from the analysis\n",
    "- Include interesting insights and graphs from previous sections\n",
    "- Share ideas for future work on the same topic using other relevant datasets\n",
    "- Share links to resources you found useful during your analysis\n",
    "\n",
    "\n",
    "#### Step 6: Make a submission & share your work\n",
    "\n",
    "- Upload your notebook to your Jovian.ml profile using `jovian.commit`.\n",
    "- **Make a submission here**: https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "- Share your work on the forum: https://jovian.ml/forum/t/course-project-on-exploratory-data-analysis-discuss-and-share-your-work/11684\n",
    "\n",
    "- Browse through projects shared by other participants and give feedback\n",
    "\n",
    "\n",
    "#### (Optional) Step 7: Write a blog post\n",
    "\n",
    "- A blog post is a great way to present and showcase your work.  \n",
    "- Sign up on [Medium.com](https://medium.com) to write a blog post for your project.\n",
    "- Copy over the explanations from your Jupyter notebook into your blog post, and [embed code cells & outputs](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e)\n",
    "- Check out the Jovian.ml Medium publication for inspiration: https://medium.com/jovianml\n",
    "\n",
    "\n",
    "\n",
    "### Recommended Datasets\n",
    "\n",
    "\n",
    "Use the following resources for finding interesting datasets:\n",
    "\n",
    "- [Recommended datasets for the course project](https://jovian.ml/forum/t/recommended-datasets-for-course-project/11711)\n",
    "- [Kaggle datasets](https://www.kaggle.com/datasets)\n",
    "- [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)\n",
    "- [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
    "- [Your personal data from online services](https://www.popsci.com/download-digital-personal-information/)\n",
    "\n",
    "\n",
    "\n",
    "### Example Projects\n",
    "\n",
    "Refer to these projects for inspiration:\n",
    "\n",
    "* [Analyzing your browser history using Pandas & Seaborn](https://medium.com/free-code-camp/understanding-my-browsing-pattern-using-pandas-and-seaborn-162b97e33e51)\n",
    "\n",
    "* [WhatsApp Chat Data Analysis](https://jovian.ml/PrajwalPrashanth/whatsapp-chat-data-analysis)\n",
    "\n",
    "* [Analyzing Covid-19 data using Pandas](https://jovian.ml/aakashns/python-pandas-data-analysis) \n",
    "\n",
    "* [Understanding the Gender Divide in Data Science Roles](https://medium.com/datadriveninvestor/exploratory-data-analysis-eda-understanding-the-gender-divide-in-data-science-roles-9faa5da44f5b)\n",
    "\n",
    "* [2019 State of Javascript Survey Results](https://2019.stateofjs.com/demographics/)\n",
    "\n",
    "* [2020 Stack Overflow Developer Survey Results](https://insights.stackoverflow.com/survey/2020)\n",
    "\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "Your submission will be evaluated using the following criteria:\n",
    "\n",
    "* Dataset must contain at least 3 columns and 150 rows of data\n",
    "* You must ask and answer at least 5 questions about the dataset\n",
    "* Your submission must include at least 5 visualizations (graphs)\n",
    "* Your submission must include explanations using markdown cells, apart from the code.\n",
    "* Your work must not be plagiarized i.e. copy-pasted from somewhere else.\n",
    "\n",
    "\n",
    "**NOTE**: Remove this cell containing the instructions before making your submission. You can do using the \"Edit > Delete Cells\" menu option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlnMnt-li-Un"
   },
   "source": [
    "# Solar India\n",
    "\n",
    "An analysis of two solar plants in India, based on the awesome Solar Power Generation Dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UE9uY5hzi-Un"
   },
   "outputs": [],
   "source": [
    "project_name = \"solar-india\" \n",
    "filename=project_name+\".ipynb\""
   ]
  },
  {
   "source": [
    "Install and import all the needed packages"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOM9hODEi-Un",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install jovian opendatasets gitpython  -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSXuHjzyi-Uo",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import jovian\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "from git import Repo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Commit method\n",
    "This is a commit method that will simultaniously upload to [jovian.ai](https://jovian.ai/charitarthchugh/solar-india) and [github.com](https://github.com/charitarthchugh/solar-india).\n",
    "This will only update in Github when there is a Git repository present because the Jovian library's commit feature only works when a git repository is detected. This function is able to push directly to the origin repository from the remote."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eHRgI1aei-Up",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "files=[f for f in os.listdir(os.getcwd()+ \"/data\") if isfile(join(os.getcwd()+ \"/data\", f))]\n",
    "def commit():\n",
    "    \"\"\"\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    jovian.commit(\n",
    "        project=project_name, \n",
    "        filename=filename,\n",
    "        files=files,\n",
    "        git_commit=True,\n",
    "        environment=\"conda\")\n",
    "    # We have to perform a manual check ourselves if there is a git repository present.\n",
    "    git_dir = os.getcwd()+\"/.git\"\n",
    "    if os.path.exists(git_dir):\n",
    "        #\n",
    "        # noinspection PyBroadException\n",
    "        try:\n",
    "            repo = Repo(git_dir)\n",
    "            origin = repo.remote(name=\"origin\")\n",
    "            origin.push()\n",
    "            print(\"Pushed Successfully!\")\n",
    "        # If there is a Failure in pushing to origin.\n",
    "        except:\n",
    "            print(\"Error occurred while pushing repository to origin\")\n",
    "    else:\n",
    "        print(\"Not in a git repository, skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnEowoDVi-Up"
   },
   "source": [
    "## Data Preparation and Cleaning\n",
    "  \n",
    "**TODO:**\n",
    "    \n",
    "1.  Download the dataset\n",
    "2.  Import into Pandas\n",
    "3.  Clean redundant data\n",
    "4.  Create Class for each plant\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "TX7jfyphi-Up",
    "outputId": "9ebe6533-efe9-4e26-d1e2-3108df0d1836",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle using opendatasets only if it does not exist already locally. Needs a Kaggle Account.\n",
    "#if not os.path.isfile(files[0]):\n",
    " #   od.download(\"https://www.kaggle.com/anikannal/solar-power-generation-data\", data_dir=os.getcwd().join(\"/data\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset Information\n",
    "\"This data has been gathered at two solar power plants in India over a 34 day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset. The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it. The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant.\"(Kaggle dataset description. Author: Ani Kannal)  \n",
    "Here is the dataset column information, split into two sections- Generation and Weather.\n",
    "\n",
    "**Generation Data**\n",
    "\n",
    "| Field                                | Description                                                                                          |\n",
    "|:------------------------------------:|:---------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                          | Date and time for each observation. Observations recorded at 15 minute intervals.                    |\n",
    "| `PLANT_ID`                           | Unique numerical ID for each solar plant.                                                            |\n",
    "| `SOURCE_KEY` (used as `INVERTER_ID`) | Unique alphanumerical ID for each inverter                                                           |\n",
    "| `DC_POWER`                           | Amount of DC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `AC_POWER`                           | Amount of AC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `TOTAL_YEILD`                        | This is the total yield for the inverter till that point in time. Does not start at 0.               |\n",
    "\n",
    "**Weather Data**\n",
    "\n",
    "| Field                                      | Description                                                                                                                 |\n",
    "|:------------------------------------------:| --------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                                | Date and time for each observation. Observations recorded at 15 minute intervals.                                           |\n",
    "| `PLANT_ID`                                 | Unique numerical ID for each solar plant.                                                                                   |\n",
    "| `SOURCE_KEY`   (used as `sensor_panel_id`) | Stands for the sensor panel id. This will be common for the entire file because there's only one sensor panel for the plant |\n",
    "| `AMBIENT_TEMPERATURE`                      | This is the ambient temperature at the plant.                                                                               |\n",
    "| `MODULE_TEMPERATURE`                       | There's a module (solar panel) attached to the sensor panel. This is the temperature reading for that module.               |\n",
    "| `IRRIDATION`                               | Amount of irradiation for the 15 minute interval.                                                                           |"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Pandas Library\n",
    "I am going to be using the [Pandas](https://pandas.pydata.org) library to interact with my dataset.\n",
    "It is a high performance library for Python to interact with datasets of many sizes that "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a2IGvzyri-Up",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "def weather_sensor_df(dataset: int) -> pd.core.frame.DataFrame:\n",
    "    tmp=pd.core.frame.DataFrame\n",
    "    if dataset==1:\n",
    "        tmp=pd.read_csv(os.getcwd()+\"/data/solar-power-generation/Plant_1_Weather_Sensor_Data.csv\")\n",
    "    elif dataset==2:\n",
    "        tmp=pd.read_csv(os.getcwd()+\"/data/solar-power-generation/Plant_2_Weather_Sensor_Data.csv\")\n",
    "    # Drop SOURCE_KEY too for same reason--> now it is sensor_panel_id, a property of this class\n",
    "    tmp.drop(columns=[\"PLANT_ID\",\"SOURCE_KEY\"], inplace=True)\n",
    "    return tmp\n",
    "def generation_df(dataset):\n",
    "    if dataset==1:\n",
    "        tmp=pd.read_csv(os.getcwd()+\"/data/solar-power-generation/Plant_1_Generation_Data.csv\")\n",
    "    elif dataset==2:\n",
    "        tmp=pd.read_csv(os.getcwd()+\"/data/solar-power-generation/Plant_2_Generation_Data.csv\")\n",
    "    # Have already saved the PLANT_ID as id, a property of this class\n",
    "    tmp.drop(columns=[\"PLANT_ID\"], inplace=True)\n",
    "    # Rename SOURCE_KEY to INVERTER_ID to make it clearer\n",
    "    tmp.rename(columns={ \"SOURCE_KEY\":\"INVERTER_ID\"},inplace=True)\n",
    "    return tmp"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Class for Plant 1 and initialize it"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Plant1:\n",
    "    id = 4135001\n",
    "    sensor_panel_id = \"HmiyD2TTLFNqkNe\"\n",
    "    generation_df = generation_df(1)\n",
    "    weather_sensor_df = weather_sensor_df(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307
    },
    "id": "eRRdcG96i-Up",
    "outputId": "e5336529-7028-4766-a246-467fc0bc2f0c",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "plant1=Plant1()\n",
    "plant1.generation_df"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Create Class for Plant 2 and initialize it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Plant2:\n",
    "    id = 4136001\n",
    "    sensor_panel_id = \"iq8k7ZNt4Mwm3w0\"\n",
    "    generation_df = generation_df(2)\n",
    "    weather_sensor_df = weather_sensor_df(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plant2=Plant2()\n",
    "plant2.generation_df"
   ]
  },
  {
   "source": [
    "#### Customize Matplotlib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"]='sans-serif'\n",
    "plt.rcParams['font.sans-serif']='Poppins-Regular'\n",
    "plt.rcParams['axes.edgecolor']='#333F4B'\n",
    "plt.rcParams['axes.linewidth']=2\n",
    "plt.rcParams['xtick.color']='#333F4B'\n",
    "plt.rcParams['ytick.color']='#333F4B'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rEc8REjx8Bs"
   },
   "source": [
    "#### Update in Jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SGX48qri-Up",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG1u7rq1i-Uq"
   },
   "source": [
    "## Exploratory Analysis and Visualization\n",
    "\n",
    "**TODO**  \n",
    "Answer exploratory questions.  \n",
    "1.   What is the distribution of ambient temperature in May-June 2015 for each of the solar plants?  \n",
    "2.   How many unique inverters are there for each plant? What is the total yeild of each inverter over a period of 34 days?    \n",
    "3.   What is the average total yeild for the inverters at each plant?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2: How many unique inverters are there for each plant? How much energy(DC and AC) does each inverter generate during a period of 34 days?\n",
    "\n",
    "**STEPS**  \n",
    "\n",
    "1. Get and save the list of unique inverters using `pd.dataframe.unique` for each plant\n",
    "    * I will be storing this in NumPy arrays. NumPy is a high performace library for numerical computing and analysis. \n",
    "2. Count the number of inverters.\n",
    "3. For every inverter in the list, do final yeild-initial yeild to find the change in the yeild.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GAdrhcUDi-Uq",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "source": [
    "# Get the list of inverters at every plant.\n",
    "plant_1_inverters = plant1.generation_df.INVERTER_ID.unique()\n",
    "plant_2_inverters = plant2.generation_df.INVERTER_ID.unique()\n",
    "print(\"Inverters at plant 1:\\n{}\".format(plant_1_inverters))\n",
    "print(\"\\nInverters at plant 2:\\n{}\".format(plant_2_inverters))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyX4YlYui-Uq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of inverters\n",
    "plant_1_inverters_count=len(plant_1_inverters)\n",
    "plant_2_inverters_count=len(plant_2_inverters)\n",
    "print(\"# of inverters at Plant 1: {}\".format(plant_1_inverters_count))\n",
    "print(\"# of inverters at Plant 2: {}\".format(plant_2_inverters_count))"
   ]
  },
  {
   "source": [
    "#### Get the Yeilds for each inverter at each plant.  \n",
    "**STEPS**  \n",
    "1. Get the minimum and maximum values of each inverter using `pd.groupby()`  \n",
    "2. Compute the delta and add it to the dataframe.  \n",
    "3. Create numerical aliases for each inverter.  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_yields( df : pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    # Gets the min and max \n",
    "    result = df.groupby('INVERTER_ID')['TOTAL_YIELD'].agg(['max','min'])\n",
    "    result['delta'] = result['max']-result['min']\n",
    "    \n",
    "    # Creates aliases\n",
    "    alias = np.zeros(result.shape[0]).astype(int)\n",
    "    for i in range(result.shape[0]):\n",
    "        alias[i] = i+1\n",
    "    result['alias'] = alias\n",
    "    \n",
    "    return result\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5v4qdwq0i-Uq",
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plant_1_yields = get_yields(plant1.generation_df)\n",
    "plant_1_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.hlines(y=plant_1_yields.alias,xmin=200000,xmax=plant_1_yields.delta,color='#007acc', alpha=0.2, linewidth=5,);\n",
    "plt.plot(plant_1_yields.delta,plant_1_yields.alias,\"o\", markersize=5, color='#007ACC', alpha=0.6);\n",
    "ax.set_xlabel(\"Energy Generated\",fontsize=15, fontweight='black', color = '#333F4B')\n",
    "ax.set_ylabel('Inverters', fontsize=15, fontweight='black', color = '#333F4B');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plant_2_yields = get_yields(plant2.generation_df)\n",
    "plant_2_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10));\n",
    "plt.hlines(y=plant_2_yields.alias,xmin=200000,xmax=plant_2_yields.delta,color='#007acc', alpha=0.2, linewidth=5,);\n",
    "plt.plot(plant_2_yields.delta,plant_2_yields.alias,\"o\", markersize=5, color='#007ACC', alpha=0.6);\n",
    "ax.set_xlabel(\"Energy Generated\",fontsize=15, fontweight='black', color = '#333F4B');\n",
    "ax.set_ylabel('Inverters', fontsize=15, fontweight='black', color = '#333F4B');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZzF_nc0i-Uq",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkqoTN9fi-Uq"
   },
   "source": [
    "## Asking and Answering Questions\n",
    "\n",
    "**TODO**\n",
    "\n",
    "1.   [Can we identify faulty or suboptimally performing equipment during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "2.   [Can we identify the need for panel cleaning/maintenance during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJrnDiO-i-Uq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Can we identify faulty or suboptimally performing equipment during the time period?\n",
    "**At Plant 1:**\n",
    "1. There is a clear indication that the inverters are undeperforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e1FI8qE6i-Uq"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plant_1_inverters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-111df7414150>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mplant_1_inverters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0;34m\"\\t\"\u001B[0m\u001B[0;34m+\u001B[0m\u001B[0mplant_1_inverters\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m12\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mavg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m22\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m1\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m12\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mi\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plant_1_inverters' is not defined"
     ]
    }
   ],
   "source": [
    "print(plant_1_inverters[1]+\"\\t\"+plant_1_inverters[12])\n",
    "avg=0\n",
    "for i in range(0,22):\n",
    "    if i==1 or i==12:\n",
    "        i+=1\n",
    "    else:\n",
    "        avg+=plant_1_yields[\"delta\"][i]\n",
    "print(avg/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a50z-ePii-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYMPOlqZi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9RfCjR-i-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNBwU4KMi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTxLLV5gi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJfeEG7Fi-Uq"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj3srQ4Ri-Uq"
   },
   "source": [
    "## Inferences and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4js0mZx3i-Uq"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_zyDCFi-Ur"
   },
   "source": [
    "## References and Future Work\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezzi4hrJi-Ur"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXUiVbbli-Ur"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "iG1u7rq1i-Uq",
    "VkqoTN9fi-Uq",
    "xj3srQ4Ri-Uq",
    "3x_zyDCFi-Ur"
   ],
   "name": "solar-india.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "solar-india",
   "language": "python",
   "name": "solar-india"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}