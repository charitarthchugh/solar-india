{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqupkZYoi-Un"
   },
   "source": [
    "### Data Analysis with Python: Zero to Pandas - Course Project Guidelines\n",
    "#### (remove this cell before submission)\n",
    "\n",
    "Make submissions here:  https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "\n",
    "This is the starter notebook for the course project for [Data Analysis with Python: Zero to Pandas](https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas). For the course project, you will pick a real-world dataset of your choice and apply the concepts learned in this course to perform exploratory data analysis. Use this starter notebook as an outline for your project (you can also start with an empty new notebook). Focus on the documentation and presentation - this Jupyter notebook will also serve as a project report, so make sure to include detailed explanations wherever possible using Markdown cells.\n",
    "\n",
    "#### Step 1: Select a real-world dataset \n",
    "\n",
    "- Find and download an interesting real-world dataset (see the Recommended Datasets section below for ideas). \n",
    "\n",
    "- The dataset should contain tabular data (rows & columns), preferably in CSV/JSON/XLS or other formats that can be read using Pandas. If it's not in a compatible format, you may have to write some code to convert it to a desired format.\n",
    "- The dataset should contain at least 3 columns and 150 rows of data. You can also combine data from multiple sources to create a large enough dataset.\n",
    "\n",
    "\n",
    "#### Step 2: Perform data preparation & cleaning\n",
    "\n",
    "- Load the dataset into a data frame using Pandas\n",
    "- Explore the number of rows & columns, ranges of values etc.\n",
    "- Handle missing, incorrect and invalid data\n",
    "- Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.)\n",
    "\n",
    "\n",
    "#### Step 3: Perform exploratory Analysis & Visualization\n",
    "\n",
    "- Compute the mean, sum, range and other interesting statistics for numeric columns\n",
    "- Explore distributions of numeric columns using histograms etc.\n",
    "- Explore relationship between columns using scatter plots, bar charts etc.\n",
    "- Make a note of interesting insights from the exploratory analysis\n",
    "\n",
    "#### Step 4: Ask & answer questions about the data\n",
    "\n",
    "- Ask at least 5 interesting questions about your dataset\n",
    "- Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib/Seaborn\n",
    "- Create new columns, merge multiple datasets and perform grouping/aggregation wherever necessary\n",
    "- Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does\n",
    "\n",
    "\n",
    "#### Step 5: Summarize your inferences & write a conclusion\n",
    "\n",
    "- Write a summary of what you've learned from the analysis\n",
    "- Include interesting insights and graphs from previous sections\n",
    "- Share ideas for future work on the same topic using other relevant datasets\n",
    "- Share links to resources you found useful during your analysis\n",
    "\n",
    "\n",
    "#### Step 6: Make a submission & share your work\n",
    "\n",
    "- Upload your notebook to your Jovian.ml profile using `jovian.commit`.\n",
    "- **Make a submission here**: https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "- Share your work on the forum: https://jovian.ml/forum/t/course-project-on-exploratory-data-analysis-discuss-and-share-your-work/11684\n",
    "\n",
    "- Browse through projects shared by other participants and give feedback\n",
    "\n",
    "\n",
    "#### (Optional) Step 7: Write a blog post\n",
    "\n",
    "- A blog post is a great way to present and showcase your work.  \n",
    "- Sign up on [Medium.com](https://medium.com) to write a blog post for your project.\n",
    "- Copy over the explanations from your Jupyter notebook into your blog post, and [embed code cells & outputs](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e)\n",
    "- Check out the Jovian.ml Medium publication for inspiration: https://medium.com/jovianml\n",
    "\n",
    "\n",
    "\n",
    "### Recommended Datasets\n",
    "\n",
    "\n",
    "Use the following resources for finding interesting datasets:\n",
    "\n",
    "- [Recommended datasets for the course project](https://jovian.ml/forum/t/recommended-datasets-for-course-project/11711)\n",
    "- [Kaggle datasets](https://www.kaggle.com/datasets)\n",
    "- [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)\n",
    "- [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
    "- [Your personal data from online services](https://www.popsci.com/download-digital-personal-information/)\n",
    "\n",
    "\n",
    "\n",
    "### Example Projects\n",
    "\n",
    "Refer to these projects for inspiration:\n",
    "\n",
    "* [Analyzing your browser history using Pandas & Seaborn](https://medium.com/free-code-camp/understanding-my-browsing-pattern-using-pandas-and-seaborn-162b97e33e51)\n",
    "\n",
    "* [WhatsApp Chat Data Analysis](https://jovian.ml/PrajwalPrashanth/whatsapp-chat-data-analysis)\n",
    "\n",
    "* [Analyzing Covid-19 data using Pandas](https://jovian.ml/aakashns/python-pandas-data-analysis) \n",
    "\n",
    "* [Understanding the Gender Divide in Data Science Roles](https://medium.com/datadriveninvestor/exploratory-data-analysis-eda-understanding-the-gender-divide-in-data-science-roles-9faa5da44f5b)\n",
    "\n",
    "* [2019 State of Javascript Survey Results](https://2019.stateofjs.com/demographics/)\n",
    "\n",
    "* [2020 Stack Overflow Developer Survey Results](https://insights.stackoverflow.com/survey/2020)\n",
    "\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "Your submission will be evaluated using the following criteria:\n",
    "\n",
    "* Dataset must contain at least 3 columns and 150 rows of data\n",
    "* You must ask and answer at least 5 questions about the dataset\n",
    "* Your submission must include at least 5 visualizations (graphs)\n",
    "* Your submission must include explanations using markdown cells, apart from the code.\n",
    "* Your work must not be plagiarized i.e. copy-pasted from somewhere else.\n",
    "\n",
    "\n",
    "**NOTE**: Remove this cell containing the instructions before making your submission. You can do using the \"Edit > Delete Cells\" menu option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlnMnt-li-Un"
   },
   "source": [
    "# Solar India\n",
    "\n",
    "An analysis of a solar plant in India, based on the awesome [Solar Power Generation Dataset](https://www.kaggle.com/anikannal/solar-power-generation-data).\n",
    "I am only focusing on the first plant in an effort to increase the quality of the analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset Information\n",
    "\"This data has been gathered at two solar power plants in India over a 34-day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset.\n",
    "The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it.\n",
    "The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant.\"(Kaggle dataset description. Author: Ani Kannal)\n",
    "Here is the dataset column information, split into two sections- Generation and Weather.\n",
    "\n",
    "**Generation Data**: The solar energy generation and conversion data collected by sensors at the plant\n",
    "\n",
    "| Field                                | Description                                                                                          |\n",
    "|:------------------------------------:|:---------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                          | Date and time for each observation. Observations recorded at 15 minute intervals.                    |\n",
    "| `PLANT_ID`                           | Unique numerical ID for each solar plant.                                                            |\n",
    "| `SOURCE_KEY` (used as `INVERTER_ID`) | Unique alphanumerical ID for each inverter                                                           |\n",
    "| `DC_POWER`                           | Amount of DC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `AC_POWER`                           | Amount of AC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `TOTAL_YEILD`                        | This is the total yield of power converted  for the inverter till that point in time. Does not start at 0.               |\n",
    "\n",
    "**Weather Data**: The weather data collected by the sensors of the plant. \n",
    "\n",
    "| Field                                      | Description                                                                                                                 |\n",
    "|:------------------------------------------:| --------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                                | Date and time for each observation. Observations recorded at 15 minute intervals.                                           |\n",
    "| `PLANT_ID`                                 | Unique numerical ID for each solar plant.                                                                                   |\n",
    "| `SOURCE_KEY` (used as `sensor_panel_id`) | Stands for the sensor panel id. This will be common for the entire file because there's only one sensor panel for the plant |\n",
    "| `AMBIENT_TEMPERATURE`                      | This is the ambient temperature at the plant.                                                                               |\n",
    "| `MODULE_TEMPERATURE`                       | There's a module (solar panel) attached to the sensor panel. This is the temperature reading for that module.               |\n",
    "| `IRRIDATION`                               | Amount of irradiation for the 15 minute interval.                                                                           |  \n",
    "\n",
    "**Before** we start doing any analysis of the data, it is necessary to install some packages from pip, the Python package manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qOM9hODEi-Un"
   },
   "outputs": [],
   "source": [
    "!pip install jovian opendatasets -U -q\n",
    "# You may need to install gitpython "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dSXuHjzyi-Uo"
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import jovian\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings as warn\n",
    "from IPython.core.display import display\n",
    "from os.path import isfile, join\n",
    "from git import Repo\n",
    "warn.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "project_name = \"solar-india\"; filename=project_name+\".ipynb\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **Side note**: Commit method\n",
    "This Jupyter Notebook lives both on Jovian and in a GitHub repository. This is a commit method that will simultaneously update on [Jovian](https://jovian.ai/charitarthchugh/solar-india) and [github.com](https://github.com/charitarthchugh/solar-india).\n",
    "This will only update in Github when there is a Git repository present because the Jovian library's commit feature only works when a git repository is detected (i.e. when you have forked the repository and doing development locally). This still requires an account on Jovian though. This function is able to push directly to the origin repository from the remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eHRgI1aei-Up"
   },
   "outputs": [],
   "source": [
    "files=[f for f in os.listdir(os.getcwd()+ \"/data\") if isfile(join(os.getcwd()+ \"/data\", f))]\n",
    "def commit():\n",
    "    jovian.commit(\n",
    "        project=project_name, \n",
    "        filename=filename,\n",
    "        files=files,\n",
    "        git_commit=True,\n",
    "        environment=\"conda\")\n",
    "    # We have to perform a manual check ourselves if there is a git repository present.\n",
    "    git_dir = os.getcwd()+\"/.git\"\n",
    "    if os.path.exists(git_dir):\n",
    "        try:\n",
    "            repo = Repo(git_dir)\n",
    "            origin = repo.remote(name=\"origin\")\n",
    "            origin.push()\n",
    "            print(\"[Git] Pushed Successfully!\")\n",
    "        # If there is a failure in pushing to origin.\n",
    "        except EnvironmentError:\n",
    "            print(\"Error occurred while pushing repository to origin\")\n",
    "    else:\n",
    "        print(\"Not in a git repository, skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnEowoDVi-Up"
   },
   "source": [
    "## Data Preparation and Cleaning\n",
    "  \n",
    "**TODO:**\n",
    "    \n",
    "1.  Download the dataset\n",
    "2.  Import into Pandas\n",
    "3.  Clean redundant data\n",
    "4.  Create Class for each plant\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "TX7jfyphi-Up",
    "outputId": "9ebe6533-efe9-4e26-d1e2-3108df0d1836"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle using opendatasets only if it does not exist already. Needs a Kaggle Account.\n",
    "data_dir=os.getcwd()+\"/data/solar-power-generation/\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    od.download(\"https://www.kaggle.com/anikannal/solar-power-generation-data\",data_dir=data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Pandas Library\n",
    "I am going to be using the [Pandas](https://pandas.pydata.org) library to interact with my dataset. It is a high performance library for Python for data manipulation and analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create Class for Plant 1 and initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weather_sensor_df():\n",
    "    \"\"\"\n",
    "    Properly load the weather sensor data\n",
    "    \"\"\"\n",
    "    tmp=pd.read_csv(data_dir+\"Plant_1_Weather_Sensor_Data.csv\")\n",
    "    \n",
    "    # Dropping source key because it is the same throughout the dataset\n",
    "    tmp.drop(columns=[\"PLANT_ID\",\"SOURCE_KEY\"], inplace=True)\n",
    "    # In the dataset, the DATE_TIME is of type object. \n",
    "    # This will convert it into timestamp data. \n",
    "    tmp[\"DATE_TIME\"]=pd.to_datetime(tmp[\"DATE_TIME\"])\n",
    "    return tmp\n",
    "\n",
    "def generation_df():\n",
    "    \"\"\"\n",
    "    Properly load the generation data\n",
    "    \"\"\"\n",
    "    tmp=pd.read_csv(data_dir+\"Plant_1_Generation_Data.csv\")\n",
    "    # Plant ID stays constant throughout the dataset and it is a\n",
    "    tmp.drop(columns=[\"PLANT_ID\"], inplace=True)\n",
    "    # In the dataset, the DATE_TIME is of type object. \n",
    "    # This will convert it into timestamp data\n",
    "    tmp[\"DATE_TIME\"]=pd.to_datetime(tmp[\"DATE_TIME\"])\n",
    "    # Rename SOURCE_KEY to INVERTER_ID to make it clearer\n",
    "    tmp.rename(columns={ \"SOURCE_KEY\":\"INVERTER_ID\"},inplace=True)\n",
    "    return tmp\n",
    "\n",
    "class Plant1:\n",
    "    \"\"\"\n",
    "    Contains properties and data of the first plant in the dataset. \n",
    "    \"\"\"\n",
    "    id = 4135001\n",
    "    sensor_panel_id = \"HmiyD2TTLFNqkNe\"\n",
    "    generation_df = generation_df()\n",
    "    weather_sensor_df = weather_sensor_df()\n",
    "# Initialize the class\n",
    "plant1=Plant1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize Matplotlib\n",
    "Matplotlib is a statistical software that creates visualizations of data. Here I will be customizing it slightly to have better visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"]='sans-serif'\n",
    "plt.rcParams['font.sans-serif']='Ubuntu'\n",
    "plt.rcParams['axes.edgecolor']='#333F4B'\n",
    "plt.rcParams['axes.linewidth']=2\n",
    "plt.rcParams['xtick.color']='#333F4B'\n",
    "plt.rcParams['ytick.color']='#333F4B'\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rEc8REjx8Bs"
   },
   "source": [
    "#### Update in Jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_SGX48qri-Up"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG1u7rq1i-Uq"
   },
   "source": [
    "## Exploratory Data Analysis and Visualization\n",
    "\n",
    "Let's learn and dive into the dataset!  \n",
    "\n",
    "**TODO**  \n",
    "Answer these exploratory questions:  \n",
    "\n",
    "    1.   What is the range of maximum daily ambient and module temperatures from May to June of 2020?\n",
    "    2.   What is the distribution for irradiation at the plant?  \n",
    "    3.   What is the efficiency of the solar panels at the plant? \n",
    "    4.   How many unique inverters are at the plant? What is the total yeild of each inverter over a period of 34 days?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About Plant 1\n",
    "[According to the author of the dataset,](https://www.kaggle.com/anikannal/solar-power-generation-data/discussion/185351)\n",
    "Plant 1 is located near [Gandikotta, Andhra](https://goo.gl/maps/VuGM2osR8FLPRpJR6) Pradesh. After some research, I found\n",
    "that Plant 1 is about 1 hour away from Gandikotta, in [Ponnampale, Andhra Pradesh](https://goo.gl/maps/BDaRknPKYsTpTgRA6)\n",
    "(there are a couple solar power plants in the area, but this one was the closest).\n",
    "[According to Wikipedia,](https://en.wikipedia.org/wiki/Kadapa_Ultra_Mega_Solar_Park) this plant has an area allotment\n",
    "of about 24 square kilometers (5928 acres), and a currently commissioned capacity of 250 megawatts. The planned capacity is 1,000\n",
    "megawatts, which is in various stages of construction.  \n",
    "<img src=\"https://github.com/charitarthchugh/solar-india/blob/main/images/kadaps_solar_power_plant.png?raw=true\"></img>\n"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What is the change in ambient and module temperature during May to June 2020 at the solar plant?\n",
    "\n",
    "We can easily do this by first plotting the data using Matplotlib to get an overall look at the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,12), dpi=100,)\n",
    "plt.plot(plant1.weather_sensor_df.DATE_TIME,plant1.weather_sensor_df.AMBIENT_TEMPERATURE, color='#4C566A', label=\"Ambient\")\n",
    "plt.plot(plant1.weather_sensor_df.DATE_TIME,plant1.weather_sensor_df.MODULE_TEMPERATURE, color=\"#88C0D0\", label=\"Module\")\n",
    "plt.legend()\n",
    "fig.autofmt_xdate(rotation=45)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title(\"Ambient and Module Temperatures at Plant 1\",fontsize=22, fontweight='black',color='#333F4B')\n",
    "ax.set_xlabel(\"Date\",fontsize=18, fontweight='black', color = '#333F4B')\n",
    "ax.set_ylabel(\"Temperature, Degrees Celsius\", fontsize=18, fontweight='black', color='#333F4B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that both the ambient and module temperatures start to decrease from May 25, 2020. This is consistent with the [climate in India](https://en.wikipedia.org/wiki/Climate_of_India), as summer ends in May and the monsoon season starts in June."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What is the distribution for irradiation at the plant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax= plt.subplots(figsize=(20,12),dpi=50)\n",
    "plt.plot(plant1.weather_sensor_df.DATE_TIME,plant1.weather_sensor_df.IRRADIATION, color='#4C566A', label=\"Irradiation\") \n",
    "ax.set_title(\"Irradiation at Plant 1\",fontsize=22, fontweight='black',color='#333F4B')\n",
    "ax.set_xlabel(\"Date\",fontsize=18, fontweight='black', color = '#333F4B')\n",
    "ax.set_ylabel(\"Irradiation\", fontsize=18, fontweight='black', color='#333F4B')\n",
    "fig.autofmt_xdate(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Groupby time\n",
    "dfg = plant1.weather_sensor_df.groupby(plant1.weather_sensor_df[\"DATE_TIME\"].dt.time)\n",
    "\n",
    "# create a dict of dataframes, where the key is an isoformat datetime.time\n",
    "df_times = {g.isoformat(): data for g, data in dfg}\n",
    "plt.plot(df_times[\"13:00:00\"].DATE_TIME, df_times[\"13:00:00\"].AMBIENT_TEMPERATURE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, this looks roughly the same as the weather data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 3: How many unique inverters are there at Plant 1? How much energy does each inverter convert(DC to AC) during a period of 34 days?\n",
    "\n",
    "**STEPS**  \n",
    "\n",
    "1. Get and save the list of unique inverters using `pd.dataframe.unique` for each plant\n",
    "    * I will be storing using NumPy arrays. NumPy is a high performance library for numerical computing and analysis.\n",
    "2. Count the number of inverters.\n",
    "3. For every inverter in the list, do final yield-initial yield to find the change in the yield.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAdrhcUDi-Uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of inverters at every plant.\n",
    "plant_1_inverters = plant1.generation_df.INVERTER_ID.unique()\n",
    "print(\"Inverters at plant 1:\\n{}\".format(plant_1_inverters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyX4YlYui-Uq"
   },
   "outputs": [],
   "source": [
    "# Count the number of inverters\n",
    "plant_1_inverters_count=len(plant_1_inverters)\n",
    "print(\"# of inverters at Plant 1: {}\".format(plant_1_inverters_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the yeilds for each inverter at each plant.  \n",
    "**STEPS**  \n",
    "1. Get the minimum and maximum values of each inverter using `pd.groupby()`  \n",
    "2. Compute the delta and add it to the dataframe.  \n",
    "3. Create numerical aliases for each inverter.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_1_yields=plant1.generation_df.groupby('INVERTER_ID')['TOTAL_YIELD'].agg(['max','min'])\n",
    "plant_1_yields['delta']=plant_1_yields['max']-plant_1_yields['min']\n",
    "alias = np.zeros(plant_1_yields.shape[0]).astype(int)\n",
    "for i in range(plant_1_yields.shape[0]):\n",
    "    alias[i] = i+1\n",
    "plant_1_yields['alias']=alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.hlines(y=plant_1_yields.alias,xmin=200000,xmax=plant_1_yields.delta,color='#007acc', alpha=0.2, linewidth=5,)\n",
    "plt.plot(plant_1_yields.delta,plant_1_yields.alias,\"o\", markersize=5, color='#007ACC', alpha=0.6)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_title(\"Total Energy Generated by each inverter\")\n",
    "ax.set_xlabel(\"Energy Generated\",fontsize=15, fontweight='black', color = '#333F4B')\n",
    "ax.set_ylabel('Inverters', fontsize=15, fontweight='black', color = '#333F4B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e1FI8qE6i-Uq"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkqoTN9fi-Uq"
   },
   "source": [
    "## Asking and Answering Questions\n",
    "\n",
    "**TODO**\n",
    "\n",
    "1.   [Can we identify faulty or suboptimally performing equipment during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "2.   [Can we identify the need for panel cleaning/maintenance during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJrnDiO-i-Uq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Can we identify faulty or suboptimally performing equipment during the time period?  \n",
    "\n",
    "\n",
    "1.\n",
    "There is a clear indication that two inverters (with the id: `1IF53ai7Xc0U56Y` and `ih0vzX44oOqAx2f` respectively) are likely\n",
    "undeperforming. Their total yields over the 34-day period are 16% and 17.5% respectively less than the average of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "a50z-ePii-Uq"
   },
   "outputs": [],
   "source": [
    "# print(\"Plant 1 Inverter {} percent difference: {} %\".format(plant_1_inverters[0],(100*(plant_1_yields[\"delta\"][0]-avg)/avg)))\n",
    "# print(\"Plant 1 Inverter {} percent difference: {} %\".format(plant_1_inverters[11],(100*(plant_1_yields[\"delta\"][11]-avg)/avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "UYMPOlqZi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9RfCjR-i-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNBwU4KMi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTxLLV5gi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJfeEG7Fi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj3srQ4Ri-Uq"
   },
   "source": [
    "## Inferences and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4js0mZx3i-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_zyDCFi-Ur"
   },
   "source": [
    "## References and Future Work\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXUiVbbli-Ur"
   },
   "source": [
    "Firstly, I would like to thank [Aakash NS and the rest of the team](https://www.linkedin.com/company/jovianai) at [Jovian](https://jovian.ai) for creating both the Zero to Pandas and Zero To GANs courses in collaboration with [FreeCodeCamp.org](https://freecodecamp.org).\n",
    "\n",
    "Major thanks to [Ani Kannal](https://www.kaggle.com/anikannal) on Kaggle for sharing this fantastic dataset with good descriptions.\n",
    "\n",
    "In addition, I would like to thank [Aero Engy on Stack Overflow](https://stackoverflow.com/users/1106634/aero-engy) for helping me with one of my questions.\n",
    "I would also like to thank [Carmine Minichini](https://www.kaggle.com/virosky) for publishing [this](https://www.kaggle.com/virosky/how-to-manage-a-solar-power-plant) great analysis on Plant 1.\n",
    "\n",
    "In the future, I hope to use machine learning on this dataset to create a model that detects when the solar panels need to be cleaned and that predicts the solar power generation for the next couple of days.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezzi4hrJi-Ur"
   },
   "outputs": [],
   "source": [
    "commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar-india",
   "language": "python",
   "name": "solar-india"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}