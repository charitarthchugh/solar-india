{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqupkZYoi-Un"
   },
   "source": [
    "### Data Analysis with Python: Zero to Pandas - Course Project Guidelines\n",
    "#### (remove this cell before submission)\n",
    "\n",
    "Make submissions here:  https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "\n",
    "This is the starter notebook for the course project for [Data Analysis with Python: Zero to Pandas](https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas). For the course project, you will pick a real-world dataset of your choice and apply the concepts learned in this course to perform exploratory data analysis. Use this starter notebook as an outline for your project (you can also start with an empty new notebook). Focus on the documentation and presentation - this Jupyter notebook will also serve as a project report, so make sure to include detailed explanations wherever possible using Markdown cells.\n",
    "\n",
    "#### Step 1: Select a real-world dataset \n",
    "\n",
    "- Find and download an interesting real-world dataset (see the Recommended Datasets section below for ideas). \n",
    "\n",
    "- The dataset should contain tabular data (rows & columns), preferably in CSV/JSON/XLS or other formats that can be read using Pandas. If it's not in a compatible format, you may have to write some code to convert it to a desired format.\n",
    "- The dataset should contain at least 3 columns and 150 rows of data. You can also combine data from multiple sources to create a large enough dataset.\n",
    "\n",
    "\n",
    "#### Step 2: Perform data preparation & cleaning\n",
    "\n",
    "- Load the dataset into a data frame using Pandas\n",
    "- Explore the number of rows & columns, ranges of values etc.\n",
    "- Handle missing, incorrect and invalid data\n",
    "- Perform any additional steps (parsing dates, creating additional columns, merging multiple dataset etc.)\n",
    "\n",
    "\n",
    "#### Step 3: Perform exploratory Analysis & Visualization\n",
    "\n",
    "- Compute the mean, sum, range and other interesting statistics for numeric columns\n",
    "- Explore distributions of numeric columns using histograms etc.\n",
    "- Explore relationship between columns using scatter plots, bar charts etc.\n",
    "- Make a note of interesting insights from the exploratory analysis\n",
    "\n",
    "#### Step 4: Ask & answer questions about the data\n",
    "\n",
    "- Ask at least 5 interesting questions about your dataset\n",
    "- Answer the questions either by computing the results using Numpy/Pandas or by plotting graphs using Matplotlib/Seaborn\n",
    "- Create new columns, merge multiple datasets and perform grouping/aggregation wherever necessary\n",
    "- Wherever you're using a library function from Pandas/Numpy/Matplotlib etc. explain briefly what it does\n",
    "\n",
    "\n",
    "#### Step 5: Summarize your inferences & write a conclusion\n",
    "\n",
    "- Write a summary of what you've learned from the analysis\n",
    "- Include interesting insights and graphs from previous sections\n",
    "- Share ideas for future work on the same topic using other relevant datasets\n",
    "- Share links to resources you found useful during your analysis\n",
    "\n",
    "\n",
    "#### Step 6: Make a submission & share your work\n",
    "\n",
    "- Upload your notebook to your Jovian.ml profile using `jovian.commit`.\n",
    "- **Make a submission here**: https://jovian.ml/learn/data-analysis-with-python-zero-to-pandas/assignment/course-project\n",
    "- Share your work on the forum: https://jovian.ml/forum/t/course-project-on-exploratory-data-analysis-discuss-and-share-your-work/11684\n",
    "\n",
    "- Browse through projects shared by other participants and give feedback\n",
    "\n",
    "\n",
    "#### (Optional) Step 7: Write a blog post\n",
    "\n",
    "- A blog post is a great way to present and showcase your work.  \n",
    "- Sign up on [Medium.com](https://medium.com) to write a blog post for your project.\n",
    "- Copy over the explanations from your Jupyter notebook into your blog post, and [embed code cells & outputs](https://medium.com/jovianml/share-and-embed-jupyter-notebooks-online-with-jovian-ml-df709a03064e)\n",
    "- Check out the Jovian.ml Medium publication for inspiration: https://medium.com/jovianml\n",
    "\n",
    "\n",
    "\n",
    "### Recommended Datasets\n",
    "\n",
    "\n",
    "Use the following resources for finding interesting datasets:\n",
    "\n",
    "- [Recommended datasets for the course project](https://jovian.ml/forum/t/recommended-datasets-for-course-project/11711)\n",
    "- [Kaggle datasets](https://www.kaggle.com/datasets)\n",
    "- [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/index.php)\n",
    "- [awesome-public-datasets](https://github.com/awesomedata/awesome-public-datasets)\n",
    "- [Google Dataset Search](https://datasetsearch.research.google.com)\n",
    "- [Your personal data from online services](https://www.popsci.com/download-digital-personal-information/)\n",
    "\n",
    "\n",
    "\n",
    "### Example Projects\n",
    "\n",
    "Refer to these projects for inspiration:\n",
    "\n",
    "* [Analyzing your browser history using Pandas & Seaborn](https://medium.com/free-code-camp/understanding-my-browsing-pattern-using-pandas-and-seaborn-162b97e33e51)\n",
    "\n",
    "* [WhatsApp Chat Data Analysis](https://jovian.ml/PrajwalPrashanth/whatsapp-chat-data-analysis)\n",
    "\n",
    "* [Analyzing Covid-19 data using Pandas](https://jovian.ml/aakashns/python-pandas-data-analysis) \n",
    "\n",
    "* [Understanding the Gender Divide in Data Science Roles](https://medium.com/datadriveninvestor/exploratory-data-analysis-eda-understanding-the-gender-divide-in-data-science-roles-9faa5da44f5b)\n",
    "\n",
    "* [2019 State of Javascript Survey Results](https://2019.stateofjs.com/demographics/)\n",
    "\n",
    "* [2020 Stack Overflow Developer Survey Results](https://insights.stackoverflow.com/survey/2020)\n",
    "\n",
    "\n",
    "### Evaluation Criteria\n",
    "\n",
    "Your submission will be evaluated using the following criteria:\n",
    "\n",
    "* Dataset must contain at least 3 columns and 150 rows of data\n",
    "* You must ask and answer at least 5 questions about the dataset\n",
    "* Your submission must include at least 5 visualizations (graphs)\n",
    "* Your submission must include explanations using markdown cells, apart from the code.\n",
    "* Your work must not be plagiarized i.e. copy-pasted from somewhere else.\n",
    "\n",
    "\n",
    "**NOTE**: Remove this cell containing the instructions before making your submission. You can do using the \"Edit > Delete Cells\" menu option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlnMnt-li-Un"
   },
   "source": [
    "# Solar India\n",
    "\n",
    "An analysis of two solar plants in India, based on the awesome Solar Power Generation Dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "UE9uY5hzi-Un"
   },
   "outputs": [],
   "source": [
    "project_name = \"solar-india\"; filename=project_name+\".ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dataset Information\n",
    "\"This data has been gathered at two solar power plants in India over a 34 day period. It has two pairs of files - each pair has one power generation dataset and one sensor readings dataset. The power generation datasets are gathered at the inverter level - each inverter has multiple lines of solar panels attached to it. The sensor data is gathered at a plant level - single array of sensors optimally placed at the plant.\"(Kaggle dataset description. Author: Ani Kannal)  \n",
    "Here is the dataset column information, split into two sections- Generation and Weather.\n",
    "\n",
    "**Generation Data**: The solar energy generation and conversion data collected by sensors at the plant\n",
    "\n",
    "| Field                                | Description                                                                                          |\n",
    "|:------------------------------------:|:---------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                          | Date and time for each observation. Observations recorded at 15 minute intervals.                    |\n",
    "| `PLANT_ID`                           | Unique numerical ID for each solar plant.                                                            |\n",
    "| `SOURCE_KEY` (used as `INVERTER_ID`) | Unique alphanumerical ID for each inverter                                                           |\n",
    "| `DC_POWER`                           | Amount of DC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `AC_POWER`                           | Amount of AC power generated by the inverter `SOURCE_KEY`, in kilowatts, in this 15 minute interval. |\n",
    "| `TOTAL_YEILD`                        | This is the total yield of power converted  for the inverter till that point in time. Does not start at 0.               |\n",
    "\n",
    "**Weather Data**: The weather data collected by the sensors of the plant. \n",
    "\n",
    "| Field                                      | Description                                                                                                                 |\n",
    "|:------------------------------------------:| --------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `DATE_TIME`                                | Date and time for each observation. Observations recorded at 15 minute intervals.                                           |\n",
    "| `PLANT_ID`                                 | Unique numerical ID for each solar plant.                                                                                   |\n",
    "| `SOURCE_KEY`   (used as `sensor_panel_id`) | Stands for the sensor panel id. This will be common for the entire file because there's only one sensor panel for the plant |\n",
    "| `AMBIENT_TEMPERATURE`                      | This is the ambient temperature at the plant.                                                                               |\n",
    "| `MODULE_TEMPERATURE`                       | There's a module (solar panel) attached to the sensor panel. This is the temperature reading for that module.               |\n",
    "| `IRRIDATION`                               | Amount of irradiation for the 15 minute interval.                                                                           |  \n",
    "\n",
    "**Before** we start doing any analysis of the data, it is necessary to install some packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "qOM9hODEi-Un"
   },
   "outputs": [],
   "source": [
    "!pip install jovian opendatasets gitpython  -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "dSXuHjzyi-Uo"
   },
   "outputs": [],
   "source": [
    "import jovian\n",
    "import opendatasets as od\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings as warn\n",
    "import datetime as dt\n",
    "from os.path import isfile, join\n",
    "from git import Repo\n",
    "warn.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### **Sidenote**: Commit method\n",
    "This Jupyter Notebook lives both on Jovian and in a GitHub repository. This is a commit method that will simultaniously update on [Jovian](https://jovian.ai/charitarthchugh/solar-india) and [github.com](https://github.com/charitarthchugh/solar-india).\n",
    "This will only update in Github when there is a Git repository present because the Jovian library's commit feature only works when a git repository is detected (i. e. when you have forked the repository and doing development locally). This still requires an account on Jovian though. This function is able to push directly to the origin repository from the remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "eHRgI1aei-Up"
   },
   "outputs": [],
   "source": [
    "files=[f for f in os.listdir(os.getcwd()+ \"/data\") if isfile(join(os.getcwd()+ \"/data\", f))]\n",
    "def commit():\n",
    "    jovian.commit(\n",
    "        project=project_name, \n",
    "        filename=filename,\n",
    "        files=files,\n",
    "        git_commit=True,\n",
    "        environment=\"conda\")\n",
    "    # We have to perform a manual check ourselves if there is a git repository present.\n",
    "    git_dir = os.getcwd()+\"/.git\"\n",
    "    if os.path.exists(git_dir):\n",
    "        try:\n",
    "            repo = Repo(git_dir)\n",
    "            origin = repo.remote(name=\"origin\")\n",
    "            origin.push()\n",
    "            print(\"Pushed Successfully!\")\n",
    "        # If there is a failure in pushing to origin.\n",
    "        except:\n",
    "            print(\"Error occurred while pushing repository to origin\")\n",
    "    else:\n",
    "        print(\"Not in a git repository, skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnEowoDVi-Up"
   },
   "source": [
    "## Data Preparation and Cleaning\n",
    "  \n",
    "**TODO:**\n",
    "    \n",
    "1.  Download the dataset\n",
    "2.  Import into Pandas\n",
    "3.  Clean redundant data\n",
    "4.  Create Class for each plant\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "id": "TX7jfyphi-Up",
    "outputId": "9ebe6533-efe9-4e26-d1e2-3108df0d1836"
   },
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle using opendatasets only if it does not exist already. Needs a Kaggle Account.\n",
    "data_dir=os.getcwd()+\"/data/solar-power-generation/\"\n",
    "if not os.path.isdir(data_dir):\n",
    "    od.download(\"https://www.kaggle.com/anikannal/solar-power-generation-data\",data_dir=os.getcwd()+\"/data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Pandas Library\n",
    "I am going to be using the [Pandas](https://pandas.pydata.org) library to interact with my dataset. It is a high performance library for Python for data manipulation and analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "a2IGvzyri-Up",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weather_sensor_df(dataset: int) -> pd.core.frame.DataFrame:\n",
    "    \n",
    "    if dataset==1:\n",
    "        tmp=pd.read_csv(data_dir+\"Plant_1_Weather_Sensor_Data.csv\")\n",
    "    elif dataset==2:\n",
    "        tmp=pd.read_csv(data_dir+\"Plant_2_Weather_Sensor_Data.csv\")\n",
    "    \n",
    "    # Dropping source key because it is the same throughout the dataset\n",
    "    tmp.drop(columns=[\"PLANT_ID\",\"SOURCE_KEY\"], inplace=True)\n",
    "    # Convert DATE_TIME to Panda's date time format.  \n",
    "    tmp[\"DATE_TIME\"]=pd.to_datetime(tmp[\"DATE_TIME\"])\n",
    "    return tmp\n",
    "def generation_df(dataset):\n",
    "    if dataset==1:\n",
    "        tmp=pd.read_csv(data_dir+\"Plant_1_Generation_Data.csv\")\n",
    "    elif dataset==2:\n",
    "        tmp=pd.read_csv(data_dir+\"Plant_2_Generation_Data.csv\")\n",
    "    # Plant ID stays constant throughout the dataset and it is a \n",
    "    tmp.drop(columns=[\"PLANT_ID\"], inplace=True)\n",
    "    tmp[\"DATE_TIME\"]=pd.to_datetime(tmp[\"DATE_TIME\"])\n",
    "    # Rename SOURCE_KEY to INVERTER_ID to make it clearer\n",
    "    tmp.rename(columns={ \"SOURCE_KEY\":\"INVERTER_ID\"},inplace=True)\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create Class for Plant 1 and initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Plant1:\n",
    "    \"\"\"\n",
    "    Contains properties and data of the first plant in the dataset. \n",
    "    \"\"\"\n",
    "    id = 4135001\n",
    "    sensor_panel_id = \"HmiyD2TTLFNqkNe\"\n",
    "    generation_df = generation_df(1)\n",
    "    weather_sensor_df = weather_sensor_df(1)\n",
    "\n",
    "plant1=Plant1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Class for Plant 2 and initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Plant2:\n",
    "    \"\"\"\n",
    "    Contains properties and data of the second plant in the dataset. \n",
    "    \"\"\"\n",
    "    id = 4136001\n",
    "    sensor_panel_id = \"iq8k7ZNt4Mwm3w0\"\n",
    "    generation_df = generation_df(2)\n",
    "    weather_sensor_df = weather_sensor_df(2)\n",
    "plant2=Plant2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Customize Matplotlib\n",
    "Matplotlib is a statistical software that creates vizualizations of data. Here I will be customizing it slightly to have better vizualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"]='sans-serif'\n",
    "plt.rcParams['font.sans-serif']='Ubuntu'\n",
    "plt.rcParams['axes.edgecolor']='#333F4B'\n",
    "plt.rcParams['axes.linewidth']=2\n",
    "plt.rcParams['xtick.color']='#333F4B'\n",
    "plt.rcParams['ytick.color']='#333F4B'\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rEc8REjx8Bs"
   },
   "source": [
    "#### Update in Jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_SGX48qri-Up"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iG1u7rq1i-Uq"
   },
   "source": [
    "## Exploratory Analysis and Visualization\n",
    "\n",
    "Let's learn and dive into the dataset!  \n",
    "\n",
    "**TODO**  \n",
    "Answer these exploratory questions:  \n",
    "\n",
    "    1.   What is the distribution of ambient temperature in May to June of 2020 for each of the solar plants?  \n",
    "    2.   How many unique inverters are there for each plant? What is the total yeild of each inverter over a period of 34 days?    \n",
    "    3.   What is the average total yeild for the inverters at each plant?  \n"
   ]
  },
  {
   "source": [
    "### Question 1: What is the change in ambient temperature and module temperatures in May to June of 2020 for each of the solar plants?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       AMBIENT_TEMPERATURE  MODULE_TEMPERATURE  IRRADIATION\n",
       "count          3182.000000         3182.000000  3182.000000\n",
       "mean             25.531606           31.091015     0.228313\n",
       "std               3.354856           12.261222     0.300836\n",
       "min              20.398505           18.140415     0.000000\n",
       "25%              22.705182           21.090553     0.000000\n",
       "50%              24.613814           24.618060     0.024653\n",
       "75%              27.920532           41.307840     0.449588\n",
       "max              35.252486           65.545714     1.221652"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AMBIENT_TEMPERATURE</th>\n      <th>MODULE_TEMPERATURE</th>\n      <th>IRRADIATION</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3182.000000</td>\n      <td>3182.000000</td>\n      <td>3182.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>25.531606</td>\n      <td>31.091015</td>\n      <td>0.228313</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.354856</td>\n      <td>12.261222</td>\n      <td>0.300836</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>20.398505</td>\n      <td>18.140415</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>22.705182</td>\n      <td>21.090553</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>24.613814</td>\n      <td>24.618060</td>\n      <td>0.024653</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>27.920532</td>\n      <td>41.307840</td>\n      <td>0.449588</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>35.252486</td>\n      <td>65.545714</td>\n      <td>1.221652</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "plant1.weather_sensor_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 2: How many unique inverters are there for each plant? How much energy does each inverter convert(DC to AC) during a period of 34 days?\n",
    "\n",
    "**STEPS**  \n",
    "\n",
    "1. Get and save the list of unique inverters using `pd.dataframe.unique` for each plant\n",
    "    * I will be storing this in NumPy arrays. NumPy is a high performace library for numerical computing and analysis. \n",
    "2. Count the number of inverters.\n",
    "3. For every inverter in the list, do final yeild-initial yeild to find the change in the yeild.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAdrhcUDi-Uq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the list of inverters at every plant.\n",
    "plant_1_inverters = plant1.generation_df.INVERTER_ID.unique()\n",
    "plant_2_inverters = plant2.generation_df.INVERTER_ID.unique()\n",
    "print(\"Inverters at plant 1:\\n{}\".format(plant_1_inverters))\n",
    "print(\"\\nInverters at plant 2:\\n{}\".format(plant_2_inverters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dyX4YlYui-Uq"
   },
   "outputs": [],
   "source": [
    "# Count the number of inverters\n",
    "plant_1_inverters_count=len(plant_1_inverters)\n",
    "plant_2_inverters_count=len(plant_2_inverters)\n",
    "print(\"# of inverters at Plant 1: {}\".format(plant_1_inverters_count))\n",
    "print(\"# of inverters at Plant 2: {}\".format(plant_2_inverters_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the Yeilds for each inverter at each plant.  \n",
    "**STEPS**  \n",
    "1. Get the minimum and maximum values of each inverter using `pd.groupby()`  \n",
    "2. Compute the delta and add it to the dataframe.  \n",
    "3. Create numerical aliases for each inverter.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yields( df : pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    # Gets the min and max \n",
    "    result = df.groupby('INVERTER_ID')['TOTAL_YIELD'].agg(['max','min'])\n",
    "    result['delta'] = result['max']-result['min']\n",
    "    \n",
    "    # Creates aliases\n",
    "    alias = np.zeros(result.shape[0]).astype(int)\n",
    "    for i in range(result.shape[0]):\n",
    "        alias[i] = i+1\n",
    "    result['alias'] = alias\n",
    "    \n",
    "    return result\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5v4qdwq0i-Uq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plant_1_yields = get_yields(plant1.generation_df)\n",
    "plant_1_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10))\n",
    "plt.hlines(y=plant_1_yields.alias,xmin=200000,xmax=plant_1_yields.delta,color='#007acc', alpha=0.2, linewidth=5,)\n",
    "plt.plot(plant_1_yields.delta,plant_1_yields.alias,\"o\", markersize=5, color='#007ACC', alpha=0.6)\n",
    "ax.set_xlabel(\"Energy Generated\",fontsize=15, fontweight='black', color = '#333F4B')\n",
    "ax.set_ylabel('Inverters', fontsize=15, fontweight='black', color = '#333F4B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plant_2_yields = get_yields(plant2.generation_df)\n",
    "plant_2_yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(10,10));\n",
    "plt.hlines(y=plant_2_yields.alias,xmin=200000,xmax=plant_2_yields.delta,color='#007acc', alpha=0.2, linewidth=5,);\n",
    "plt.plot(plant_2_yields.delta,plant_2_yields.alias,\"o\", markersize=5, color='#007ACC', alpha=0.6);\n",
    "ax.set_xlabel(\"Energy Generated\",fontsize=15, fontweight='black', color = '#333F4B');\n",
    "ax.set_ylabel('Inverters', fontsize=15, fontweight='black', color = '#333F4B');\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "e1FI8qE6i-Uq"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1 Inverter 1BY6WEcLGh8j5v7 percent difference: -7.700878981727381 %\nPlant 1 Inverter iCRJl6heRkivqQ3 percent difference: -9.153886937516452 %\n"
     ]
    }
   ],
   "source": [
    "avg=0\n",
    "for i in plant_1_yields.delta:\n",
    "    avg+=i\n",
    "avg=avg/22\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZzF_nc0i-Uq"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VkqoTN9fi-Uq"
   },
   "source": [
    "## Asking and Answering Questions\n",
    "\n",
    "**TODO**\n",
    "\n",
    "1.   [Can we identify faulty or suboptimally performing equipment during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "2.   [Can we identify the need for panel cleaning/maintenance during the time period?](https://www.kaggle.com/anikannal/solar-power-generation-data?select=Plant_2_Weather_Sensor_Data.csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJrnDiO-i-Uq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Can we identify faulty or suboptimally performing equipment during the time period?  \n",
    "\n",
    "**At Plant 1:**  \n",
    "1.\n",
    "There is a clear indication that two inverters (with the id: `1IF53ai7Xc0U56Y` and `ih0vzX44oOqAx2f` respectively) are likely undeperforming.\n",
    "Their total yields over the 34 day period are 16% and 17.5% respectivlely less than the average of the dataset.  \n",
    "**At Plant 2:**  \n",
    "1. No inferences can be made about the performace of the inverters at this plant because of the high variance of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "a50z-ePii-Uq"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Plant 1 Inverter 1BY6WEcLGh8j5v7 percent difference: -7.700878981727381 %\nPlant 1 Inverter iCRJl6heRkivqQ3 percent difference: -9.153886937516452 %\n"
     ]
    }
   ],
   "source": [
    " print(\"Plant 1 Inverter {} percent difference: {} %\".format(plant_1_inverters[0],(100*(plant_1_yields[\"delta\"][0]-avg)/avg)))\n",
    "print(\"Plant 1 Inverter {} percent difference: {} %\".format(plant_1_inverters[11],(100*(plant_1_yields[\"delta\"][11]-avg)/avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYMPOlqZi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9RfCjR-i-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNBwU4KMi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTxLLV5gi-Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJfeEG7Fi-Uq"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj3srQ4Ri-Uq"
   },
   "source": [
    "## Inferences and Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4js0mZx3i-Uq"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x_zyDCFi-Ur"
   },
   "source": [
    "## References and Future Work\n",
    "\n"
   ]
  },
  {
   "source": [
    "Firstly, I would like to thank [Aakash NS and the rest of the team](https://www.linkedin.com/company/jovianai) at [Jovian](https://jovian.ai) for creating both the Zero to Pandas and Zero To GANs courses in collaboration with FreeCodeCamp.  \n",
    "\n",
    "Major thanks to [Ani Kannal](https://www.kaggle.com/anikannal) on Kaggle for sharing this fantastic dataset with good descriptions.\n",
    "\n",
    "In addition, I would like to thank [Aero Engy on Stack Overflow](https://stackoverflow.com/users/1106634/aero-engy) for helping me with one of my questions. I would also like to thank (Carmine Minichini)[https://www.kaggle.com/virosky] for publishing [this](https://www.kaggle.com/virosky/how-to-manage-a-solar-power-plant) great analysis on Plant 1. \n",
    "\n",
    "In the future, I hope to use machine learning on this dataset to create a model that detects when the solar panels need to be cleaned and that predicts the solar power generation for the next couple of days.  "
   ],
   "cell_type": "markdown",
   "metadata": {
    "id": "NXUiVbbli-Ur"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ezzi4hrJi-Ur"
   },
   "outputs": [],
   "source": [
    "#commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solar-india",
   "language": "python",
   "name": "solar-india"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}